{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925d746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as nrc_py\n",
    "import pandas as pnl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72de0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_csv(path):\n",
    "\n",
    "    assert os.path.exists(path), f'File not found: {path}!'\n",
    "    assert os.path.splitext(path)[\n",
    "        -1] == '.csv', f'Unsupported file type {os.path.splitext(path)[-1]}!'\n",
    "\n",
    "    data = pnl_data.read_csv(path)\n",
    "    column_list = data.columns.values.tolist()\n",
    "    column_list.remove('id')\n",
    "\n",
    "    if 'target' in column_list:\n",
    "        # for the training dataset, label column is provided.\n",
    "        column_list.remove('target')\n",
    "        X = data[column_list].values\n",
    "        y = data['target'].astype('int').values\n",
    "        return X, y\n",
    "    else:\n",
    "        # for the testing dataset, label column is not provided.\n",
    "        X = data[column_list].values\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2074f28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...  \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...   \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...   \n",
       "2   2     1.0 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  ...   \n",
       "3   3     1.0  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  ...   \n",
       "4   4     1.0  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3 -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is for data analyzing\n",
    "\n",
    "\"\"\"\n",
    "data = pnl_data.read_csv('../dont-overfit-ii/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0be613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Columns: 302 entries, id to 299\n",
      "dtypes: float64(301), int64(1)\n",
      "memory usage: 590.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(250, 302)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is for data analyzing\n",
    "\n",
    "\"\"\"\n",
    "data.info()\n",
    "data.shape # with column id and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b09cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>124.500000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044652</td>\n",
       "      <td>0.126344</td>\n",
       "      <td>0.018436</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.065720</td>\n",
       "      <td>-0.106112</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.128952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72.312977</td>\n",
       "      <td>0.480963</td>\n",
       "      <td>0.998354</td>\n",
       "      <td>1.009314</td>\n",
       "      <td>1.021709</td>\n",
       "      <td>1.011751</td>\n",
       "      <td>1.035411</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.006657</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011416</td>\n",
       "      <td>0.972567</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>1.057414</td>\n",
       "      <td>1.038389</td>\n",
       "      <td>0.967661</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>1.008099</td>\n",
       "      <td>0.971219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.319000</td>\n",
       "      <td>-2.931000</td>\n",
       "      <td>-2.477000</td>\n",
       "      <td>-2.359000</td>\n",
       "      <td>-2.566000</td>\n",
       "      <td>-2.845000</td>\n",
       "      <td>-2.976000</td>\n",
       "      <td>-3.444000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.804000</td>\n",
       "      <td>-2.443000</td>\n",
       "      <td>-2.757000</td>\n",
       "      <td>-2.466000</td>\n",
       "      <td>-3.287000</td>\n",
       "      <td>-3.072000</td>\n",
       "      <td>-2.634000</td>\n",
       "      <td>-2.776000</td>\n",
       "      <td>-3.211000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.644750</td>\n",
       "      <td>-0.739750</td>\n",
       "      <td>-0.425250</td>\n",
       "      <td>-0.686500</td>\n",
       "      <td>-0.659000</td>\n",
       "      <td>-0.643750</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>-0.550750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-0.510500</td>\n",
       "      <td>-0.535750</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>-0.818500</td>\n",
       "      <td>-0.821000</td>\n",
       "      <td>-0.605500</td>\n",
       "      <td>-0.751250</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-0.754250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.016500</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>186.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.620750</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.783250</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797250</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.650250</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.654250</td>\n",
       "      <td>0.503250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.567000</td>\n",
       "      <td>2.419000</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>2.771000</td>\n",
       "      <td>2.901000</td>\n",
       "      <td>2.793000</td>\n",
       "      <td>2.546000</td>\n",
       "      <td>2.846000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865000</td>\n",
       "      <td>2.801000</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>2.596000</td>\n",
       "      <td>2.226000</td>\n",
       "      <td>3.131000</td>\n",
       "      <td>3.236000</td>\n",
       "      <td>2.626000</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>2.771000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      target           0           1           2           3  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean   124.500000    0.640000    0.023292   -0.026872    0.167404    0.001904   \n",
       "std     72.312977    0.480963    0.998354    1.009314    1.021709    1.011751   \n",
       "min      0.000000    0.000000   -2.319000   -2.931000   -2.477000   -2.359000   \n",
       "25%     62.250000    0.000000   -0.644750   -0.739750   -0.425250   -0.686500   \n",
       "50%    124.500000    1.000000   -0.015500    0.057000    0.184000   -0.016500   \n",
       "75%    186.750000    1.000000    0.677000    0.620750    0.805000    0.720000   \n",
       "max    249.000000    1.000000    2.567000    2.419000    3.392000    2.771000   \n",
       "\n",
       "                4           5           6           7  ...         290  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  ...  250.000000   \n",
       "mean     0.001588   -0.007304    0.032052    0.078412  ...    0.044652   \n",
       "std      1.035411    0.955700    1.006657    0.939731  ...    1.011416   \n",
       "min     -2.566000   -2.845000   -2.976000   -3.444000  ...   -2.804000   \n",
       "25%     -0.659000   -0.643750   -0.675000   -0.550750  ...   -0.617000   \n",
       "50%     -0.023000    0.037500    0.060500    0.183500  ...    0.067500   \n",
       "75%      0.735000    0.660500    0.783250    0.766250  ...    0.797250   \n",
       "max      2.901000    2.793000    2.546000    2.846000  ...    2.865000   \n",
       "\n",
       "              291         292         293         294         295         296  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean     0.126344    0.018436   -0.012092   -0.065720   -0.106112    0.046472   \n",
       "std      0.972567    0.954229    0.960630    1.057414    1.038389    0.967661   \n",
       "min     -2.443000   -2.757000   -2.466000   -3.287000   -3.072000   -2.634000   \n",
       "25%     -0.510500   -0.535750   -0.657000   -0.818500   -0.821000   -0.605500   \n",
       "50%      0.091000    0.057500   -0.021000   -0.009000   -0.079500    0.009500   \n",
       "75%      0.804250    0.631500    0.650250    0.739500    0.493000    0.683000   \n",
       "max      2.801000    2.736000    2.596000    2.226000    3.131000    3.236000   \n",
       "\n",
       "              297         298         299  \n",
       "count  250.000000  250.000000  250.000000  \n",
       "mean     0.006452    0.009372   -0.128952  \n",
       "std      0.998984    1.008099    0.971219  \n",
       "min     -2.776000   -3.211000   -3.500000  \n",
       "25%     -0.751250   -0.550000   -0.754250  \n",
       "50%      0.005500   -0.009000   -0.132500  \n",
       "75%      0.794250    0.654250    0.503250  \n",
       "max      2.626000    3.530000    2.771000  \n",
       "\n",
       "[8 rows x 302 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is for data analyzing\n",
    "\n",
    "\"\"\"\n",
    "data.isnull().sum()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28e409e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.151498</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>-0.018465</td>\n",
       "      <td>-0.176930</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>-0.016244</td>\n",
       "      <td>0.084511</td>\n",
       "      <td>-0.037473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026179</td>\n",
       "      <td>0.104573</td>\n",
       "      <td>-0.076038</td>\n",
       "      <td>0.061150</td>\n",
       "      <td>0.022245</td>\n",
       "      <td>-0.064452</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>-0.032826</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>-0.022638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.151498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>-0.073319</td>\n",
       "      <td>-0.015141</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>-0.114726</td>\n",
       "      <td>-0.050329</td>\n",
       "      <td>-0.057063</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039675</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>-0.088930</td>\n",
       "      <td>-0.034363</td>\n",
       "      <td>-0.031964</td>\n",
       "      <td>-0.170501</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>0.056810</td>\n",
       "      <td>-0.134760</td>\n",
       "      <td>-0.075475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029519</td>\n",
       "      <td>0.108966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003871</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>-0.047819</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.070091</td>\n",
       "      <td>-0.022537</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023230</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>-0.143668</td>\n",
       "      <td>-0.007530</td>\n",
       "      <td>-0.060824</td>\n",
       "      <td>-0.024839</td>\n",
       "      <td>-0.051288</td>\n",
       "      <td>0.029143</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.038523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.018465</td>\n",
       "      <td>-0.073319</td>\n",
       "      <td>-0.003871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>-0.018884</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>-0.028023</td>\n",
       "      <td>-0.032914</td>\n",
       "      <td>-0.066416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006300</td>\n",
       "      <td>-0.077365</td>\n",
       "      <td>-0.021583</td>\n",
       "      <td>-0.054171</td>\n",
       "      <td>-0.046174</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>-0.127499</td>\n",
       "      <td>0.065883</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>-0.056612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.176930</td>\n",
       "      <td>-0.015141</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031620</td>\n",
       "      <td>0.088980</td>\n",
       "      <td>-0.050191</td>\n",
       "      <td>0.024674</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111172</td>\n",
       "      <td>-0.027842</td>\n",
       "      <td>-0.013653</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.051292</td>\n",
       "      <td>-0.028690</td>\n",
       "      <td>-0.071835</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.025507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.064452</td>\n",
       "      <td>-0.170501</td>\n",
       "      <td>-0.024839</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>-0.028690</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.050318</td>\n",
       "      <td>0.026868</td>\n",
       "      <td>-0.023192</td>\n",
       "      <td>0.032648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030738</td>\n",
       "      <td>-0.020251</td>\n",
       "      <td>0.015083</td>\n",
       "      <td>-0.139025</td>\n",
       "      <td>-0.015920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072721</td>\n",
       "      <td>-0.036572</td>\n",
       "      <td>-0.034341</td>\n",
       "      <td>0.097052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.027832</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>-0.051288</td>\n",
       "      <td>-0.127499</td>\n",
       "      <td>-0.071835</td>\n",
       "      <td>0.034551</td>\n",
       "      <td>-0.030017</td>\n",
       "      <td>0.070294</td>\n",
       "      <td>0.036903</td>\n",
       "      <td>-0.006235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.042079</td>\n",
       "      <td>-0.045879</td>\n",
       "      <td>-0.011766</td>\n",
       "      <td>0.125693</td>\n",
       "      <td>-0.072721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002007</td>\n",
       "      <td>0.056297</td>\n",
       "      <td>0.040264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.032826</td>\n",
       "      <td>0.056810</td>\n",
       "      <td>0.029143</td>\n",
       "      <td>0.065883</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>0.069243</td>\n",
       "      <td>0.037912</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048496</td>\n",
       "      <td>0.066474</td>\n",
       "      <td>-0.025382</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>-0.103255</td>\n",
       "      <td>-0.036572</td>\n",
       "      <td>-0.002007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039793</td>\n",
       "      <td>-0.141078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>-0.134760</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>-0.066438</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>-0.048009</td>\n",
       "      <td>0.171640</td>\n",
       "      <td>-0.031094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125556</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>-0.005422</td>\n",
       "      <td>-0.063242</td>\n",
       "      <td>-0.034341</td>\n",
       "      <td>0.056297</td>\n",
       "      <td>0.039793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.022638</td>\n",
       "      <td>-0.075475</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>-0.056612</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>-0.010770</td>\n",
       "      <td>-0.040654</td>\n",
       "      <td>-0.084178</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.122393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>0.017763</td>\n",
       "      <td>0.126105</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>-0.081196</td>\n",
       "      <td>0.097052</td>\n",
       "      <td>0.040264</td>\n",
       "      <td>-0.141078</td>\n",
       "      <td>-0.092017</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    target         0         1         2         3         4  \\\n",
       "id      1.000000 -0.151498  0.029519 -0.018465 -0.176930  0.024949  0.016726   \n",
       "target -0.151498  1.000000  0.108966 -0.073319 -0.015141  0.011549 -0.114726   \n",
       "0       0.029519  0.108966  1.000000 -0.003871 -0.010487 -0.047819  0.013967   \n",
       "1      -0.018465 -0.073319 -0.003871  1.000000  0.013573 -0.018884  0.086743   \n",
       "2      -0.176930 -0.015141 -0.010487  0.013573  1.000000 -0.031620  0.088980   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "295    -0.064452 -0.170501 -0.024839  0.042820 -0.028690 -0.005016 -0.050318   \n",
       "296    -0.027832  0.007434 -0.051288 -0.127499 -0.071835  0.034551 -0.030017   \n",
       "297    -0.032826  0.056810  0.029143  0.065883  0.069395  0.089963  0.029747   \n",
       "298     0.000657 -0.134760  0.065951  0.055470  0.083946 -0.066438 -0.008517   \n",
       "299    -0.022638 -0.075475  0.038523 -0.056612  0.025507 -0.010770 -0.040654   \n",
       "\n",
       "               5         6         7  ...       290       291       292  \\\n",
       "id     -0.016244  0.084511 -0.037473  ... -0.026179  0.104573 -0.076038   \n",
       "target -0.050329 -0.057063  0.004239  ...  0.039675  0.055694 -0.088930   \n",
       "0       0.070091 -0.022537  0.002832  ... -0.023230  0.053416 -0.143668   \n",
       "1      -0.028023 -0.032914 -0.066416  ... -0.006300 -0.077365 -0.021583   \n",
       "2      -0.050191  0.024674  0.035260  ... -0.111172 -0.027842 -0.013653   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "295     0.026868 -0.023192  0.032648  ... -0.030738 -0.020251  0.015083   \n",
       "296     0.070294  0.036903 -0.006235  ...  0.016047  0.042079 -0.045879   \n",
       "297     0.069243  0.037912  0.014628  ...  0.048496  0.066474 -0.025382   \n",
       "298    -0.048009  0.171640 -0.031094  ... -0.125556  0.087400  0.008096   \n",
       "299    -0.084178 -0.004655 -0.122393  ...  0.082621  0.017763  0.126105   \n",
       "\n",
       "             293       294       295       296       297       298       299  \n",
       "id      0.061150  0.022245 -0.064452 -0.027832 -0.032826  0.000657 -0.022638  \n",
       "target -0.034363 -0.031964 -0.170501  0.007434  0.056810 -0.134760 -0.075475  \n",
       "0      -0.007530 -0.060824 -0.024839 -0.051288  0.029143  0.065951  0.038523  \n",
       "1      -0.054171 -0.046174  0.042820 -0.127499  0.065883  0.055470 -0.056612  \n",
       "2      -0.009691 -0.051292 -0.028690 -0.071835  0.069395  0.083946  0.025507  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "295    -0.139025 -0.015920  1.000000 -0.072721 -0.036572 -0.034341  0.097052  \n",
       "296    -0.011766  0.125693 -0.072721  1.000000 -0.002007  0.056297  0.040264  \n",
       "297     0.021148 -0.103255 -0.036572 -0.002007  1.000000  0.039793 -0.141078  \n",
       "298    -0.005422 -0.063242 -0.034341  0.056297  0.039793  1.000000 -0.092017  \n",
       "299     0.012255 -0.081196  0.097052  0.040264 -0.141078 -0.092017  1.000000  \n",
       "\n",
       "[302 rows x 302 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is for data analyzing\n",
    "\n",
    "\"\"\"\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4353d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (250, 300)\n",
      "Shape of y: (250,)\n"
     ]
    }
   ],
   "source": [
    "X, y = read_data_from_csv('../dont-overfit-ii/train.csv')\n",
    "print('Shape of X:', X.shape)  # sample, feature\n",
    "print('Shape of y:', y.shape)  # sample (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33a6fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.098  2.165  0.681 ... -0.414  1.038 -1.065]\n",
      " [ 1.081 -0.973 -0.383 ... -1.099 -0.936  0.973]\n",
      " [-0.523 -0.089 -0.348 ...  0.004  0.8   -1.211]\n",
      " ...\n",
      " [ 1.411 -1.465  0.119 ...  0.76   0.168 -0.719]\n",
      " [ 0.62   1.04   0.184 ... -0.805  2.029 -0.423]\n",
      " [ 0.489  0.403  0.139 ... -1.454 -0.625  1.474]]\n",
      "[-0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276 -2.246  1.825\n",
      " -0.912 -0.107  0.305  0.102  0.826  0.417  0.177 -0.673 -0.503  1.864\n",
      "  0.41  -1.927  0.102 -0.931  1.763  1.449 -1.097 -0.686 -0.25  -1.859\n",
      "  1.125  1.009 -2.296  0.385 -0.876  1.528 -0.144 -1.078 -0.403  0.005\n",
      "  1.405 -0.044 -0.458  0.579  2.929  0.833  0.761  0.737  0.669  0.717\n",
      " -1.542 -1.847 -0.445  1.238 -0.84  -1.891 -1.531 -0.396 -0.927  2.072\n",
      "  0.946 -1.105  0.008  0.933 -1.41  -0.77   1.74  -1.504 -0.391 -1.551\n",
      " -1.415 -0.974  0.796 -2.464 -1.424  1.23   0.219  0.13  -0.371 -0.93\n",
      "  1.851  1.292 -0.38   1.318  1.146 -0.399  2.227  0.447  0.87   1.42\n",
      " -1.675  0.019  0.06   0.768  2.563  0.638  1.164  0.407 -1.556 -0.903\n",
      "  1.329  0.452 -0.704  2.218 -1.844  0.158 -1.649 -0.172 -1.167 -1.456\n",
      " -0.778  0.098 -1.627  0.405 -0.082 -0.797 -0.303  0.71  -0.252  1.92\n",
      "  0.706 -0.915  0.267 -0.607  0.966 -0.337 -2.292 -1.366 -1.085  0.278\n",
      "  0.212  1.26  -1.276 -2.013 -1.101  0.797  0.661  1.232 -0.632 -0.805\n",
      "  1.236 -1.085 -0.067 -0.661 -0.745  1.306 -0.01  -0.475 -0.613 -0.841\n",
      " -0.837  0.671  2.493  0.689  0.946  0.16  -0.607 -0.775  1.688  0.302\n",
      " -1.156 -0.718  0.126  0.745 -0.287 -0.565  0.646 -0.119 -0.675 -0.479\n",
      " -0.191 -0.454  1.314  0.74   0.999  1.242 -0.339  0.403 -1.243  1.365\n",
      "  0.03  -0.475  0.86   0.036  1.313 -0.219  1.078  1.88  -0.317 -0.443\n",
      "  1.876 -0.611  0.892  1.435 -0.226  0.311  0.139 -0.075  1.381  1.716\n",
      " -2.017 -0.485  1.906 -0.119  0.609 -0.564  0.264 -0.604 -0.733 -2.352\n",
      " -1.661  0.498 -0.841  0.907 -0.476  0.817  1.372  1.187  0.844  0.028\n",
      "  0.029 -0.808  0.253  1.005  1.413 -0.133  0.655 -0.921  0.231 -1.902\n",
      " -0.005 -1.73   1.132 -0.194  0.039  1.489 -0.328  0.966 -0.057 -0.181\n",
      "  0.723 -0.313 -0.165 -0.803  0.074 -2.851 -1.021 -0.894  0.967  0.218\n",
      " -0.692 -0.514  0.754 -1.892  0.203  2.174 -0.755 -1.053 -0.516 -1.109\n",
      " -0.681  1.25  -0.565 -1.318 -0.923  0.075 -0.704  2.457  0.771 -0.46\n",
      "  0.569 -1.32  -1.516 -2.145 -1.12   0.156  0.82  -1.049 -1.125  0.484\n",
      "  0.617  1.253  1.248  0.504 -0.802 -0.896 -1.793 -0.284 -0.601  0.569\n",
      "  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell is for data analyzing\n",
    "\n",
    "\"\"\"\n",
    "print(X)\n",
    "print(X[0])\n",
    "#print(y)  # (0, 1)\n",
    "#print(type(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d591f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "X = X.tolist()\n",
    "for i in range(0, 250):\n",
    "    X[i].append(1)\n",
    "\n",
    "print(type(X[0]))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647c00f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.081, -0.973, -0.383, 0.326, -0.428, 0.317, 1.172, 0.352, 0.004, -0.291, 2.907, 1.085, 2.144, 1.54, 0.584, 1.133, 1.098, -0.237, -0.498, 0.283, -1.1, -0.417, 1.382, -0.515, -1.519, 0.619, -0.128, 0.866, -0.54, 1.238, -0.227, 0.269, -0.39, -2.721, 1.659, 0.106, -0.121, 1.719, 0.411, -0.303, -0.307, 0.38, 0.503, -1.32, 0.339, -1.102, -0.947, 0.267, 0.695, 0.167, 0.188, -1.082, -0.872, 0.66, 0.051, 0.303, -0.553, -0.771, 0.588, 0.472, 1.315, -0.467, -0.064, 1.808, 0.633, 1.221, 1.112, 1.133, -0.543, -2.144, 0.151, -0.813, 1.966, -1.19, 0.19, -0.473, 0.002, 1.195, -0.799, 1.117, -0.759, -0.661, 0.406, -0.846, -0.035, -1.634, -0.011, 0.503, 0.61, -1.822, -0.03, 1.188, -0.006, -0.279, 1.914, 0.62, -1.495, 1.787, -0.305, 0.602, -1.208, 0.893, 0.379, 1.396, 0.581, -0.475, -0.056, -0.691, -0.783, -1.485, 1.911, -2.4, -2.372, -0.178, 1.55, -0.228, 0.674, 0.987, 1.373, -0.373, 0.629, 0.229, -0.63, -0.175, 0.548, 0.074, -2.09, -0.625, -1.131, 1.111, -0.1, 0.574, -0.66, -1.113, 0.802, -0.093, 1.302, -0.395, 0.745, -0.384, 0.066, -0.756, 0.495, -0.822, 0.135, 0.883, 0.211, -0.502, 2.506, 1.402, 1.182, -1.382, 0.448, -0.247, 0.704, 1.558, -0.075, 0.609, 1.255, -1.263, 0.613, 0.213, -1.395, 0.613, -0.865, 0.166, 0.665, -1.081, 0.94, 0.415, 0.578, -0.616, 0.987, 0.274, 0.762, 0.311, 1.832, 0.395, 1.113, -0.735, 0.643, 0.727, -0.607, -0.955, 0.009, 0.68, -0.192, 0.859, -0.354, -1.178, 1.039, -1.079, 0.668, 0.995, 0.083, -1.411, -0.591, 0.742, 1.402, -2.414, -0.551, 0.003, -0.344, -1.194, -0.106, -0.679, 0.009, 0.372, 0.025, 0.066, 1.005, -0.822, 0.468, 0.413, 0.004, 0.329, 1.213, 0.216, 0.584, -0.761, -0.151, -0.175, -0.603, 0.007, 0.075, -0.354, -0.124, 1.299, 0.85, -0.318, -0.141, 0.154, -0.441, -0.024, 0.793, -1.47, 0.386, -2.254, -0.463, 0.366, -0.676, 0.071, 0.504, 1.5, -1.16, -0.187, -0.43, -1.151, 1.764, 1.307, -0.731, -1.234, 0.96, 1.47, 0.652, 0.483, -2.015, -1.258, 0.63, 1.158, 0.971, -1.489, 0.53, 0.917, -0.094, -1.407, 0.887, -0.104, -0.583, 1.267, -1.667, -2.771, -0.516, 1.312, 0.491, 0.932, 2.064, 0.422, 1.215, 2.012, 0.043, -0.307, -0.059, 1.121, 1.333, 0.211, 1.753, 0.053, 1.274, -0.612, -0.165, -1.695, -1.257, 1.359, -0.808, -1.624, -0.458, -1.099, -0.936, 0.973, 1]\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "print(X[1])\n",
    "print(len(X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd72a2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n    The model design starts here!!!\\n    The model design starts here!!!\\n    The model design starts here!!!\\n    \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    \n",
    "    The model design starts here!!!\n",
    "    The model design starts here!!!\n",
    "    The model design starts here!!!\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c10b3051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Reference: https://towardsdatascience.com/what-is-activation-function-1464a629cdca '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step_Function(x):\n",
    "    return 1 if x > 0 else 0\n",
    "def linear_Activation_Function(a, x):\n",
    "    return a*x\n",
    "def sigmoid_Activation_Function(x):\n",
    "    return 1./(1+nrc_py.exp(-x))\n",
    "def tanh_Activation_Function(x):\n",
    "    return 2*sigmoid_Activation_Function(2*x)-1\n",
    "\"\"\" Reference: https://towardsdatascience.com/what-is-activation-function-1464a629cdca \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea39ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y)\n",
    "#print(y[0])\n",
    "import random\n",
    "def initializeWeights(y, numberOfInputs):\n",
    "    rand = []\n",
    "    for i in range(0, numberOfInputs):\n",
    "        # Last one for the Bias\n",
    "        rand.append(random.uniform(-0.01, 0.01))\n",
    "    #print(len(rand))\n",
    "    #print(nrc_py.array(rand).shape, y.shape)\n",
    "    return nrc_py.array(rand)\n",
    "\n",
    "def Layer1(x, L1): \n",
    "    for i in range(0, 100): \n",
    "        sum = 0 \n",
    "        # For the first hidden Layer, we output 100 neurons \n",
    "        for j in range(0, 301): \n",
    "            sum = sum + (x[j] * weightsForLayerOne[i][j])\n",
    "        #print(\"sum = \", sum)\n",
    "        sum = tanh_Activation_Function(sum)\n",
    "        L1.append(sum) \n",
    "        #print(sum) # For Debugging\n",
    "    return L1\n",
    "\n",
    "def Layer2(x, L2): \n",
    "    for i in range(0, 1): \n",
    "        sum = 0 \n",
    "        # For the first hidden Layer, we output 100 neurons \n",
    "        for j in range(0, 101): \n",
    "            sum = sum + (x[j] * weightsForLayerOutput[i][j])\n",
    "        #print(sum) # For Debugging\n",
    "        L2 = step_Function(sum)\n",
    "    return L2\n",
    "\n",
    "\n",
    "def Error_Function(L2, y):\n",
    "    #print(L2) # For Debugging\n",
    "    #print(y) # For Debugging\n",
    "    if L2 - y == 0:\n",
    "        return 0\n",
    "    else: return y - L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05466f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 ,  1\n",
      "Accuracy =  0.5\n",
      "125 ,  2\n",
      "Accuracy =  0.5\n",
      "125 ,  3\n",
      "Accuracy =  0.5\n",
      "125 ,  4\n",
      "Accuracy =  0.5\n",
      "125 ,  5\n",
      "Accuracy =  0.5\n",
      "126 ,  6\n",
      "Accuracy =  0.504\n",
      "126 ,  7\n",
      "Accuracy =  0.504\n",
      "126 ,  8\n",
      "Accuracy =  0.504\n",
      "126 ,  9\n",
      "Accuracy =  0.504\n",
      "126 ,  10\n",
      "Accuracy =  0.504\n",
      "126 ,  11\n",
      "Accuracy =  0.504\n",
      "126 ,  12\n",
      "Accuracy =  0.504\n",
      "125 ,  13\n",
      "Accuracy =  0.5\n",
      "125 ,  14\n",
      "Accuracy =  0.5\n",
      "125 ,  15\n",
      "Accuracy =  0.5\n",
      "125 ,  16\n",
      "Accuracy =  0.5\n",
      "125 ,  17\n",
      "Accuracy =  0.5\n",
      "124 ,  18\n",
      "Accuracy =  0.496\n",
      "125 ,  19\n",
      "Accuracy =  0.5\n",
      "125 ,  20\n",
      "Accuracy =  0.5\n",
      "125 ,  21\n",
      "Accuracy =  0.5\n",
      "125 ,  22\n",
      "Accuracy =  0.5\n",
      "125 ,  23\n",
      "Accuracy =  0.5\n",
      "125 ,  24\n",
      "Accuracy =  0.5\n",
      "125 ,  25\n",
      "Accuracy =  0.5\n",
      "124 ,  26\n",
      "Accuracy =  0.496\n",
      "124 ,  27\n",
      "Accuracy =  0.496\n",
      "124 ,  28\n",
      "Accuracy =  0.496\n",
      "124 ,  29\n",
      "Accuracy =  0.496\n",
      "124 ,  30\n",
      "Accuracy =  0.496\n",
      "123 ,  31\n",
      "Accuracy =  0.492\n",
      "124 ,  32\n",
      "Accuracy =  0.496\n",
      "124 ,  33\n",
      "Accuracy =  0.496\n",
      "124 ,  34\n",
      "Accuracy =  0.496\n",
      "124 ,  35\n",
      "Accuracy =  0.496\n",
      "124 ,  36\n",
      "Accuracy =  0.496\n",
      "123 ,  37\n",
      "Accuracy =  0.492\n",
      "123 ,  38\n",
      "Accuracy =  0.492\n",
      "123 ,  39\n",
      "Accuracy =  0.492\n",
      "123 ,  40\n",
      "Accuracy =  0.492\n",
      "123 ,  41\n",
      "Accuracy =  0.492\n",
      "123 ,  42\n",
      "Accuracy =  0.492\n",
      "123 ,  43\n",
      "Accuracy =  0.492\n",
      "124 ,  44\n",
      "Accuracy =  0.496\n",
      "124 ,  45\n",
      "Accuracy =  0.496\n",
      "122 ,  46\n",
      "Accuracy =  0.488\n",
      "122 ,  47\n",
      "Accuracy =  0.488\n",
      "123 ,  48\n",
      "Accuracy =  0.492\n",
      "123 ,  49\n",
      "Accuracy =  0.492\n",
      "122 ,  50\n",
      "Accuracy =  0.488\n",
      "122 ,  51\n",
      "Accuracy =  0.488\n",
      "122 ,  52\n",
      "Accuracy =  0.488\n",
      "122 ,  53\n",
      "Accuracy =  0.488\n",
      "122 ,  54\n",
      "Accuracy =  0.488\n",
      "122 ,  55\n",
      "Accuracy =  0.488\n",
      "122 ,  56\n",
      "Accuracy =  0.488\n",
      "122 ,  57\n",
      "Accuracy =  0.488\n",
      "122 ,  58\n",
      "Accuracy =  0.488\n",
      "121 ,  59\n",
      "Accuracy =  0.484\n",
      "120 ,  60\n",
      "Accuracy =  0.48\n",
      "120 ,  61\n",
      "Accuracy =  0.48\n",
      "120 ,  62\n",
      "Accuracy =  0.48\n",
      "120 ,  63\n",
      "Accuracy =  0.48\n",
      "120 ,  64\n",
      "Accuracy =  0.48\n",
      "119 ,  65\n",
      "Accuracy =  0.476\n",
      "118 ,  66\n",
      "Accuracy =  0.472\n",
      "118 ,  67\n",
      "Accuracy =  0.472\n",
      "118 ,  68\n",
      "Accuracy =  0.472\n",
      "118 ,  69\n",
      "Accuracy =  0.472\n",
      "118 ,  70\n",
      "Accuracy =  0.472\n",
      "118 ,  71\n",
      "Accuracy =  0.472\n",
      "118 ,  72\n",
      "Accuracy =  0.472\n",
      "118 ,  73\n",
      "Accuracy =  0.472\n",
      "118 ,  74\n",
      "Accuracy =  0.472\n",
      "118 ,  75\n",
      "Accuracy =  0.472\n",
      "118 ,  76\n",
      "Accuracy =  0.472\n",
      "118 ,  77\n",
      "Accuracy =  0.472\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9d6dc1b47017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m301\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;31m#print(weightsForLayerOutput[0][i]) # For Debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0mweightsForLayerOne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweightsForLayerOne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearning_Rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweightsForLayerOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mnumberOfCorrectPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumberOfCorrectPredictions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_Rate = 0.001\n",
    "Accuracy = []\n",
    "\n",
    "weightsForLayerOne = nrc_py.empty((100, 301))\n",
    "weightsForLayerOutput = nrc_py.empty((1, 101)) \n",
    "#print(weightsForLayerOne.shape) \n",
    "for i in range(0, 100): \n",
    "    weightsForLayerOne[i] = initializeWeights(weightsForLayerOne[i], 301) \n",
    "for i in range(0, 1): \n",
    "    weightsForLayerOutput[i] = initializeWeights(weightsForLayerOutput[i], 101)\n",
    "    \n",
    "#print(weightsForLayerOne) # For Debugging\n",
    "#print(weightsForLayerOutput) # For Debugging\n",
    "#print(len(weightsForLayerOne)) # For Debugging \n",
    "#print(weightsForLayerOne[1].shape) # For Debugging\n",
    "\n",
    "e = 1\n",
    "Acc = 0\n",
    "while Acc < 0.824:\n",
    "    numberOfCorrectPredictions = 0\n",
    "    for iterations in range(0, 250):\n",
    "        L1 = [] # Layer 1\n",
    "        L2 = 0 # Layer 2\n",
    "        L1 = Layer1(X[iterations], L1)\n",
    "        #print(len(L1)) # For Debugging (100)\n",
    "        L1.append(1)\n",
    "        #print(len(L1)) # For Debugging (101)\n",
    "        L2 = Layer2(L1, L2)\n",
    "        #print(L1) # For Debugging\n",
    "\n",
    "        error = Error_Function(L2, y[iterations])\n",
    "        if error != 0:\n",
    "            \"\"\"\n",
    "            for i in range(0, 101):\n",
    "                #print(weightsForLayerOutput[0][i]) # For Debugging\n",
    "                weightsForLayerOutput[0][i] = weightsForLayerOutput[0][i] + (learning_Rate * error * L1[i])\n",
    "                #print(\"update V = \", weightsForLayerOutput[0][i]) # For Debugging\n",
    "            \"\"\"\n",
    "            for i in range(0, 100):\n",
    "                for j in range(0, 301):\n",
    "                    #print(weightsForLayerOutput[0][i]) # For Debugging\n",
    "                    weightsForLayerOne[i][j] = weightsForLayerOne[i][j] + (learning_Rate * error * weightsForLayerOutput[0][i] * L1[i] * (1 - L1[i]) * X[iterations][j])\n",
    "        else:\n",
    "            numberOfCorrectPredictions = numberOfCorrectPredictions + 1\n",
    "    \n",
    "    #print(weightsForLayerOutput) # For Debugging\n",
    "    print(numberOfCorrectPredictions, \", \", e)\n",
    "    Acc = numberOfCorrectPredictions / 250\n",
    "    print(\"Accuracy = \", Acc )\n",
    "    Accuracy.append(Acc)\n",
    "    e = e + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf36ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start testing with Unseen Data\n",
    "UnseenData = read_data_from_csv('../dont-overfit-ii/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964686bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of UnseenData:', UnseenData.shape)  # k_sample, m_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UnseenData = UnseenData.tolist()\n",
    "for i in range(0, 19750):\n",
    "    UnseenData[i].append(1)\n",
    "\n",
    "print(len(UnseenData[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedUnseenLabels = []\n",
    "for iterations in range(0, 19750):\n",
    "    L1 = [] # Layer 1\n",
    "    L2 = 0 # Layer 2\n",
    "    L1 = Layer1(UnseenData[iterations], L1)\n",
    "    L1.append(1)\n",
    "    L2 = Layer2(L1, L2)\n",
    "    #print(len(L1)) # For Debugging\n",
    "    #print(L1) # For Debugging\n",
    "    predictedUnseenLabels.append(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictedUnseenLabels)) # For Debugging\n",
    "print(predictedUnseenLabels) # For Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ac4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_header = []\n",
    "for i in range(250, 20000):\n",
    "    id_header.append(i)\n",
    "\n",
    "output = pnl_data.DataFrame({'id' : id_header, 'target': predictedUnseenLabels})\n",
    "output.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xxx = pnl_data.read_csv('result.csv')\n",
    "#xxx.info()\n",
    "#xxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12698393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(len(Accuracy)) # For Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "025a25e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Accuracy)\n",
    "plt.savefig('plot_Trial5.2.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e4b4dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7c07ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
